
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    table
    {
      padding: 5px;
    }
    
    table.exp_table,td.exp_td1,td.exp_td2
    {
      padding: 8px;
      width: 850px;
          border-collapse: separate;
          border-spacing: 15px;
          margin-top: -5px;
    }

    td.exp_td1
    {
      width:50px;
    }
    td.exp_td1 img
    {
        height:100px;
        width: 100px;
    }
    table.pub_table,td.pro_td1,td.pub_td1,td.pub_td2
    {
      padding: 8px;
      width: 850px;
          border-collapse: separate;
          border-spacing: 15px;
          margin-top: 5px;
    }

    td.pub_td1
    {
      width:50px;
    }
    td.pub_td1 img
    {
        height:150px;
        width: 300px;
    }
    td.pro_td1
    {
      width:50px;
    }
    td.pro_td1 img
    {
        height:150px;
        width: 300px;
    }
  
    table.pub_table tr {
        outline: thin dotted #666666;
    }



    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 21px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    location {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 20px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
    }

    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <!--<link rel="icon" type="image/png" href="seal_icon.png">-->
  <title>Homepage - Haidong Zhu</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129383700-1"></script> -->
  <script async src="//cdn.clustrmaps.com/map_v2.js?d=U37Tp3fiJ-qk0_GIWbjGztRNJBhpmJ7DA2BtJEvpS8E&cl=ffffff&w=a"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-129383700-1');
  </script>

</head>

<body>
  <table width="850" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="65%" valign="middle">
              <p align="center">
                <name>Haidong Zhu</name>
              </p>
              <p> I am a research scientist at Waymo Research. I received my Ph.D. in Computer Science from the University of Southern California (USC) in May 2024. I have the privilege of working at the USC <a href="https://sites.usc.edu/iris-cvlab/">IRIS Computer Vision Lab</a>, advised by <a href="https://sites.usc.edu/iris-cvlab/professor-ram-nevatia/">Prof. Ram Nevatia</a>. Before that, I completed my Bachelor's Degree in Electronic Engineering from Tsinghua University in 2019.  <br/><br/>

               My research interests lie in computer vision and deep learning, especially multimodal analysis for 3-D vision and biometric understanding. <br/><br/>

          
              </p>
              
              
              <!--
              <p>
                Contact: PHE 226, MC-2073, USC, Los Angeles, CA 90089-0273
              </p>
            -->
              <p>
                <a href="mailto:luka.cro1996@gmail.com">Email</a> &nbsp&nbsp/&nbsp&nbsp&nbsp
                <a href="documents/Resume_two_page.pdf">CV</a>  &nbsp&nbsp/&nbsp&nbsp&nbsp
                <!--<a href="documents/cv-Haidong.pdf">one-page CV</a>  &nbsp&nbsp/&nbsp&nbsp&nbsp -->
                <a href="https://github.com/haidongz-usc">Github</a>   &nbsp&nbsp/&nbsp&nbsp&nbsp
                <a href="https://scholar.google.com/citations?user=-7PW10UAAAAJ&hl=en">Google Scholar</a> 
              </p>
            </td>
            <td width="35%">
              <img src="image/personal-img2.jpg" width="60%">
            </td>
          </tr>
        </table>

<!-- Experience Section -->
<table width="100%" align="center" cellspacing="0" cellpadding="20">
    <tr>
        <td valign="middle">
            <heading>Experience</heading>
            <table width="100%" class="exp_table">
                <tr>
                    <td width="70%">
                        <b>Waymo LLC</b>, New York, NY<br>
                        Research Scientist &bull; Jun. 2024 to Present<br>
                        <ul>
                            <li>Developed auto-labeling pipeline using large language models for semantic labeling of BEV data.</li>
                            <li>Implemented diffusion models for accurate road graph construction, improving baseline accuracy by 30%.</li>
                            <li>Integrated Semantic Neural Radiance Fields for efficient semantic segmentation in partially labeled scenarios.</li>
                        </ul>
                    </td>
                    <td width="12%" align="center">
                        <img src="image/waymo.png" width="110px">
                    </td>
                </tr>
            </table>
        </td>
    </tr>
</table>

<!-- Education Section -->
<table width="100%" align="center" cellspacing="0" cellpadding="20">
    <tr>
        <td valign="middle">
            <heading>Education</heading>
            <table class="exp_table">
                <tr>
                    <td width="70%">
                        <b>University of Southern California</b>, Los Angeles, CA<br>
                        Ph.D., Computer Science &bull; Aug. 2019 to May 2024
                    </td>
                    <td width="12%" align="center">
                        <img src="image/usc-logo.png" width="110px">
                    </td>
                </tr>
                <tr>
                    <td width="70%">
                        <b>Tsinghua University</b>, Beijing, China<br>
                        B.Eng., Electronic Information Science and Technology &bull; Sep. 2015 to Jul. 2019
                    </td>
                    <td width="12%" align="center">
                        <img src="image/tsinghua-logo.jpg" width="110px">
                    </td>
                </tr>
            </table>
        </td>
    </tr>
</table>

<!-- Internship and On-campus Experience -->
<table width="100%" align="center" cellspacing="0" cellpadding="20">
    <tr>
        <td valign="middle">
            <heading>Internship and On-campus Experience</heading>
            <table class="exp_table">
                <tr>
                    <td>
                        <b><a href="https://sites.usc.edu/iris-cvlab/">IRIS Computer Vision Lab</a>, USC</b>, Los Angeles, CA<br>
                        Research/Teaching Assistant &bull; Aug. 2019 to May 2024<br>
                        Advisor: Prof. <a href="https://sites.usc.edu/iris-cvlab/professor-ram-nevatia/">Ram Nevatia</a>
                        <ul>
                            <li>Enhanced 3D reconstruction methods with implicit neural representations.</li>
                            <li>Investigated biometric identification through gait and 3D body shape analysis.</li>
                            <li>Developed multimodal sentiment analysis models using self-supervised learning.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><a href="https://www.microsoft.com/applied-sciences">Applied Sciences Group</a>, Microsoft</b>, Redmond, WA<br>
                        Research Intern &bull; May 2023 to Aug. 2023<br>
                        Advisor: Dr. <a href="https://www.tianyuding.com/">Tianyu Ding</a>
                        <ul>
                            <li>Developed few-shot generalizable Neural Radiance Field (NeRF) architectures.</li>
                            <li>Implemented NeRF-based methods for interactive 3D scene editing.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><a href="https://amazon.jobs/en/teams/lab126/">Lab 126</a>, Amazon</b>, Bellevue, WA<br>
                        Applied Scientist Intern &bull; May 2022 to Aug. 2022<br>
                        Advisor: Dr. <a href="https://scholar.google.com/citations?user=qvnQQOcAAAAJ&hl=en">Yuyin Sun</a>
                        <ul>
                            <li>Designed a multimodal NeRF framework integrating RGB and depth data.</li>
                            <li>Enhanced robustness of 3D point cloud registration algorithms.</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>
                        <b><a href="https://ailab.bytedance.com/">AI Lab</a>, Bytedance Inc.</b>, Mountain View, CA<br>
                        Research Intern &bull; May 2021 to Aug. 2021<br>
                        Advisor: Dr. <a href="https://yyvettey.github.io/">Ye Yuan</a>
                        <ul>
                            <li>Developed methods for single-image-based 3D human mesh reconstruction.</li>
                            <li>Created generative models for automatic clothing geometry and texture synthesis.</li>
                        </ul>
                    </td>
                </tr>
                <!--
                <tr>
                    <td>
                        <b><a href="https://vcg.seas.harvard.edu/">Visual Computing Group</a>, Harvard University</b>, Cambridge, MA<br>
                        Undergraduate Research Intern &bull; Jul. 2018 to Sept. 2018<br>
                        Advisor: Prof. <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a>
                        <ul>
                            <li>Contributed to biologically constrained graph algorithms for connectomics.</li>
                        </ul>
                    </td>
                </tr>-->
            </table>
        </td>
    </tr>
</table>

        
        <!-- Selected Projects -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="40%" valign="middle">
            <heading>Preprint</heading>
          </td>
        </tr>
        </table>


        <table class="pub_table">


          <tbody>
            <tr>
              <td class="pub_td1"><img src="project/img/processed/llm.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>The Efficiency Spectrum of Large Language Models: An Algorithmic Survey</b>
                </div>
                <div class="authors">
                    Tianyu Ding,
                    Tianyi Chen,
                    <u>Haidong Zhu</u>,
                    Jiachen Jiang,
                    Yiqi Zhong,
                    Jinxin Zhou,
                    Guangzhi Wang,
                    Zhihui Zhu,
                    Ilya Zharkov,
                    and Luming Liang
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2312.00678">[Paper]</a>
                    <a href="https://github.com/tding1/Efficient-LLM-Survey">[Project]</a>
                </div>

            </td>
            </tr>

          </tbody>

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="40%" valign="middle">
            <heading>Selected Manuscripts</heading>
          </td>
        </tr>
        </table>


        <table class="pub_table">

          <tbody>
            <tr>
              <td class="pub_td1"><img src="project/img/processed/overview.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>CaesarNeRF: Calibrated Semantic Representation for Few-Shot Generalizable Neural Rendering</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu*</u>,
                    Tianyu Ding*,
                    Tianyi Chen,
                    Ilya Zharkov,
                    Ram Nevatia,
                    and Luming Liang
                </div>
                <div class="status">
                  Accepted to <i>European Conference on Computer Vision (<b>ECCV</b>)</i>, 2024
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2311.15510">[Paper]</a>
                    <a href="project/pdf/caesar_supp.pdf">[Supp]</a>
                    <a href="https://haidongz-usc.github.io/project/caesarnerf">[Project]</a>
                    <a href="https://github.com/haidongz-usc/CaesarNeRF">[Code]</a>
                </div>

            </td>
            </tr>

          </tbody>

          

          <tbody>
            <tr>
              <td class="pub_td1"><img src="project/img/processed/seas.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>SEAS: ShapE-Aligned Supervision for Person Re-Identification</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Pranav Budhwant,
                    Zhaoheng Zheng,
                    and Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, pp. 164-174, 2024
                </div>
                <div class="links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_SEAS_ShapE-Aligned_Supervision_for_Person_Re-Identification_CVPR_2024_paper.pdf">[Paper]</a>
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Zhu_SEAS_ShapE-Aligned_Supervision_CVPR_2024_supplemental.zip">[Supp]</a>
                </div>

            </td>
            </tr>

          </tbody>

          <tbody>
            <tr>
              <td class="pub_td1"><img src="project/img/processed/llamp.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Large Language Models are Good Prompt Learners for Low-Shot Image Classification</b>
                </div>
                <div class="authors">
                	Zhaoheng Zheng,
                	Jingmin Wei,
                	Xuefeng Hu,
                    <u>Haidong Zhu</u>,
                    and Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, pp. 28453-28462, 2024
                </div>
                <div class="links">
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zheng_Large_Language_Models_are_Good_Prompt_Learners_for_Low-Shot_Image_CVPR_2024_paper.pdf">[Paper]</a>
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Zheng_Large_Language_Models_CVPR_2024_supplemental.pdf">[Supp]</a>
                    <a href="https://github.com/zhaohengz/LLaMP">[Code]</a>
                </div>

            </td>
            </tr>

          </tbody>

          <tbody>
            <tr>
              <td class="pub_td1"><img src="project/img/processed/sharc.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>ShARc: Shape and Appearance ReCognition for Person Identification In-the-Wild</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Wanrong Zheng,
                    Zhaoheng Zheng,
                    and Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>)</i>, pp. 6290-6300, 2024
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2310.15946">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>

          <tbody>
            <tr>
              <td class="pub_td1"><img src="project/img/processed/caila.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot Learning</b>
                </div>
                <div class="authors">
                    Zhaoheng Zheng,
                    <u>Haidong Zhu</u>,
                    and Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>)</i>, pp. 1721-1731, 2024
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2305.16681">[Paper]</a>
                    <a href="https://github.com/zhaohengz/CAILA">[Code]</a>
                </div>

            </td>
            </tr>

          </tbody>


          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/gaitstr.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>GaitSTR: Gait Recognition With Sequential Two-Stream Refinement</b>
                </div>
                <div class="authors">
                    Wanrong Zheng*, 
                    <u>Haidong Zhu*</u>,
                    Zhaoheng Zheng,
                    and Ram Nevatia
                </div>
                <div class="status">
                  In <i> IEEE Transactions on Biometrics, Behavior, and Identity Science (<b>TBIOM</b>)</i>, 2024.
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2404.02345">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>        

          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/gaitref.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>GaitRef: Gait Recognition with Refined Sequential Skeletons</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu*</u>,
                    Wanrong Zheng*, 
                    Zhaoheng Zheng,
                    and Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of <i> IEEE International Joint Conference on Biometrics (<b>IJCB</b>)</i>, 2023 (Oral)
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2304.07916">[Paper]</a>
                    <a href="https://github.com/haidongz-usc/GaitRef">[Code]</a>
                </div>
                
            </td>
            </tr>

          </tbody>        
        <!--

        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="40%" valign="middle">
            <heading>Manuscripts</heading>
          </td>
        </tr>
        </table>

          
        <table class="pub_table">
        -->
          
          

          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/multinerf.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Multimodal Neural Radiance Field</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Yuyin Sun, Chi Liu, Lu Xia, Jiajia Luo, Nan Qiao, 
                    Ram Nevatia, and Cheng-Hao Kuo
                </div>
                <div class="status">
                  In <i>IEEE International Conference on Robotics and Automation (<b>ICRA</b>)</i>, pp. 9393-9399, 2023
                </div>
                <div class="links">
                    <a href="https://www.amazon.science/publications/multimodal-neural-radiance-field">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>        
          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/gaitbody.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Gait Recognition Using 3-D Human Body Shape Inference</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Zhaoheng Zheng, and
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>)</i>, pp. 909-918, 2023
                </div>
                <div class="links">
                    <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Zhu_Gait_Recognition_Using_3-D_Human_Body_Shape_Inference_WACV_2023_paper.pdf">[Paper]</a>
                    <a href="https://openaccess.thecvf.com/content/WACV2023/supplemental/Zhu_Gait_Recognition_Using_WACV_2023_supplemental.pdf">[Supp]</a>
                </div>

            </td>
            </tr>


          </tbody>    

        <!--
          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/open.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>OPEN: Order-preserving Pointcloud Encoder Decoder Network for Body Shape Refinement</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Ye Yuan,
                    Yiheng Zhu,
                    Xiao Yang, and
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>International Conference on Pattern Recognition (<b>ICPR</b>)</i>, pp. 521-527, 2022 (Oral)
                </div>
                <div class="links">
                    <a href="https://ieeexplore.ieee.org/document/9956131">[Paper]</a>
                    <a href="https://ieeexplore.ieee.org/ielx7/9956007/9955631/9956131/0006_MM.zip?arnumber=9956131">[Supp]</a>
                </div>

            </td>
            </tr>

          </tbody>        

          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/tstf.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Temporal Shift and Attention Modules for Graphical Skeleton Action Recognition</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Zhaoheng Zheng, and
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>International Conference on Pattern Recognition (<b>ICPR</b>)</i>, pp. 3145-3151, 2022
                </div>
                <div class="links">
                    <a href="https://ieeexplore.ieee.org/document/9956662">[Paper]</a>
                    <a href="https://ieeexplore.ieee.org/ielx7/9956007/9955631/9956662/0005_MM.zip?arnumber=9956662">[Supp]</a>
                </div>

            </td>
            </tr>

          </tbody>        
		  -->

          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/sentiitem.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Self-supervised Learning for Sentiment Analysis via Image-text Matching</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Zhaoheng Zheng,
                    Mohammad Soleymani, and
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>)</i>, pp. 1710-1714, 2022
                </div>
                <div class="links">
                    <a href="https://ieeexplore.ieee.org/document/9747819">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>        


          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/ltnet.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Utilizing Every Image Object for Semi-supervised Phrase Grounding</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Arka Sadhu,
                    Zhaoheng Zheng, and
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>)</i>, pp. 2210-2219, 2021
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2011.02655">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>        
          
          
          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/cdsdf.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Curriculum DeepSDF</b>
                </div>
                <div class="authors">
                    Yueqi Duan*,
                    <u>Haidong Zhu</u>*,
                    He Wang,
                    Li Yi,
                    Ram Nevatia, and 
                    Leonidas J. Guibas
                </div>
                <div class="status">
                  In <i>European Conference on Computer Vision (<b>ECCV</b>)</i>, pp. 51-67, 2020
                </div>
                <div class="links">
                      <a href="https://arxiv.org/abs/2003.08593">[Paper]</a>
                      <a href="https://github.com/haidongz-usc/Curriculum-DeepSDF">[Code]</a>
                </div>
            </td>
            </tr>

          </tbody>          
  




          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/network108.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Pick-and-Learn: Automatic Quality Evaluation for Noisy-Labeled Image Segmentation</b>
                </div>
                <div class="authors">
                <u>Haidong Zhu</u>,
                Jialin Shi, and 
                Ji Wu
                </div>
                <div class="status">
                  In Proceedings of the <i>International Conf. on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>)</i>, LNCS 11769, pp. 576-584, 2019.
                </div>
                <div class="links">
                      <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-32226-7_64.pdf">[Paper]</a>
                      <!-- <a href="https://github.com/zhuhd15/Quality-Awareness-Module">[Code]</a> -->
                </div>
            </td>
            </tr>

          </tbody>

          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/lifted-multicut.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Biologically-Constrained Graphs for Global Connectomics Reconstruction</b>
                </div>
                <div class="authors">
                  Brian Matejek,
                  Daniel Haehn,
                  <u>Haidong Zhu</u>,
                  Donglai Wei,
                  Toufiq Parag, and 
                  Hanspeter Pfister
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, pp. 2089-2098, 2019.
                </div>
                <div class="links">
                      <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Matejek_Biologically-Constrained_Graphs_for_Global_Connectomics_Reconstruction_CVPR_2019_paper.pdf">[Paper]</a>
                      <a href="http://openaccess.thecvf.com/content_CVPR_2019/supplemental/Matejek_Biologically-Constrained_Graphs_for_CVPR_2019_supplemental.pdf">[Supp]</a>
                      <a href="https://github.com/Rhoana/biologicalgraphs/">[Code]</a>
                </div>
            </td>
            </tr>

          </tbody>
        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="40%" valign="middle">
            <heading>Workshop, Survey and System Manuscrips</heading>
          </td>
        </tr>
        </table>


        <table class="pub_table">


          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/agreid.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>AG-ReID 2023: Aerial-Ground Person Re-identification Challenge Results</b>
                </div>
                <div class="authors">Kien Nguyen, Clinton Fookes, Sridha Sridharan, Feng Liu, Xiaoming Liu, Arun Ross, Dana Michalski, Huy Nguyen, Debayan Deb, Mahak Kothari, Manisha Saini, Dawei Du, Scott McCloskey, Gabriel Bertocco, Fernanda Andal√≥, Terrance E Boult, Anderson Rocha, <u>Haidong Zhu</u>, Zhaoheng Zheng, Ram Nevatia, Zaigham Randhawa, Sinan Sabri, Gianfranco Doretto
                </div>
                <div class="status">
                  In Proceedings of <i> IEEE International Joint Conference on Biometrics (<b>IJCB</b>)</i>, 2023
                </div>
                <div class="links">
                    <a href="https://cvlab.cse.msu.edu/pdfs/IJCB_AG_ReID2023_Challenge_Summary_Paper.pdf">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>        
          
          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/tempconstant.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>CAT-NeRF: Constancy-Aware Tx<sup>2</sup>Former for Dynamic Body Modeling</b>
                </div>
                <div class="authors">
                    <u>Haidong Zhu</u>,
                    Zhaoheng Zheng,
                    Wanrong Zheng, and
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>)</i>, pp. 6618-6627, 2023
                </div>
                <div class="links">
                    <a href="https://arxiv.org/abs/2304.07915">[Paper]</a>
                    <a href="https://github.com/haidongz-usc/CAT-NeRF">[Code]</a>
                    <a href="project/pdf/CVPRW23_CAT_NeRF_supp.zip">[Example Videos]</a>
                </div>

            </td>
            </tr>

          </tbody>        


          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/gaia.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>GAIA at SM-KBP 2020 - A Dockerized Multi-media Multi-lingual Knowledge Extraction, Clustering, Temporal Tracking and Hypothesis Generation System</b>
                </div>
                <div class="authors">Manling Li, Ying Lin, Tuan Manh Lai, Xiaoman Pan, Haoyang Wen, Sha Li, Zhenhailong Wang, Pengfei Yu, Lifu Huang, Di Lu, Qingyun Wang, Haoran Zhang, Qi Zeng, Chi Han, Zixuan Zhang, Yujia Qin, Xiaodan Hu, Nikolaus Parulian, Daniel Campos, Heng Ji, Brian Chen, Xudong Lin, Alireza Zareian, Amith Ananthram, Emily Allaway, Shih-Fu Chang, Kathleen McKeown, Yixiang Yao, Michael Spector, Mitchell DeHaven, Daniel Napierski, Marjorie Freedman, Pedro Szekely, <u>Haidong Zhu</u>, Ram Nevatia, Yang Bai, Yifan Wang, Ali Sadeghian, Haodi Ma, Daisy Zhe Wang
                </div>
                <div class="status">
                  In Proceedings of the <i>Thirteenth Text Analysis Conference (<b>TAC</b>)</i>, 2020
                </div>
                <div class="links">
                    <a href="https://dsr.cise.ufl.edu/wp-content/uploads/2021/02/gaia_smkbp_2020.pdf">[Paper]</a>
                </div>

            </td>
            </tr>

          </tbody>        

          <tbody> 
            <tr>
              <td class="pub_td1"><img src="project/img/processed/parr.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>CPARR: Category-based Proposal Analysis for Referring Relationships</b>
                </div>
                <div class="authors">
                    Chuanzi He,
                    <u>Haidong Zhu</u>,
                    Jiyang Gao,
                    Kan Chen, and 
                    Ram Nevatia
                </div>
                <div class="status">
                  In Proceedings of the <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>)</i>, pp. 4074-4083, 2020.
                </div>
                <div class="links">
                      <a href="https://arxiv.org/abs/2004.08028">[Paper]</a>
                </div>
            </td>
            </tr>

          </tbody>


        </table>


        <!-- Selected Systems -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="40%" valign="middle">
            <heading>Thesis</heading>
          </td>
        </tr>
        </table>
        <table class="pub_table">

          
          <tbody> 
            <tr>
              <td class="pro_td1"><img src="project/img/processed/usc-logo.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Shape-assisted Multimodal Person Re-Identification</b>
                </div>
                <div class="description">
                    &bull; Doctor of Philosophy, University of Southern California, 2024.<br/>
                    &bull; Advisor: Prof Ram Nevatia
                </div>
                <div class="links">
                      <a href="https://drive.google.com/file/d/1p26q6ea-bUOh28ya-HAY5VZmNhDAoi72/view">[Thesis]</a>
                      <a href="project/pdf/Dissertation.pdf">[Defense]</a>
                </div>
            </td>
            </tr>

          </tbody>
          <tbody> 
            <tr>
              <td class="pro_td1"><img src="project/img/processed/thu.png" class="papericon"></td>
              <td class="pub_td2">
                <div class="title">
                  <b>Deep Learning Based Target Delineation System</b>
                </div>
                <div class="description">
                    &bull; Bachelor of Engineering, Tsinghua University, 2019.<br/>
                    &bull; Advisor: Prof Ji Wu
                </div>
                <div class="links">
                      <a href="project/pdf/undergrad/undergrad_thesis.pdf">[Thesis]</a>
                      <a href="project/pdf/undergrad/v1.pdf">[Proposal]</a>
                      <a href="project/pdf/undergrad/v2.pdf">[Midterm]</a>
                      <a href="project/pdf/undergrad/v3.pdf">[Defense]</a>
                </div>
            </td>
            </tr>

          </tbody>
        </table>

        <!-- Selected Systems -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="40%" valign="middle">
            <heading>Selected Projects</heading>
          </td>
        </tr>
        </table>
        <table class="pub_table">

          <tbody> 
            <tr>
              <td class="pro_td1"><img src="project/img/processed/reasoning.jpg" class="papericon"></td>
              <td class="pub_td2">
              <div class="title">
                <b>Structural Relational Reasoning for Point Clouds </b> 
              </div>
              <div class="description">
                   &bull; Introduced structural relational network (SRN) for reasoning.<br/>
                   &bull; Improved the results on public point cloud datasets.

                </div>
                <div class="status">
                   In Proceedings of the <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, pp. 949-958, 2019.
              </div>
                <div class="links">
                      <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Duan_Structural_Relational_Reasoning_of_Point_Clouds_CVPR_2019_paper.pdf">[Paper]</a>
                </div>
            </td>
            </tr>

          </tbody>
          <tbody> 
            <tr>
              <td class="pro_td1"><img src="project/img/processed/face-recognition-system.png" class="papericon"></td>
              <td class="pub_td2">
              <div class="title">
                <b>Online Big Data Face Recognition System  </b>
              </div>
              <div class="description">
                   &bull; Real time face recognition with data from Internet.<br/>
                   &bull; Big data management policy for renewing database.<br/>
                   &bull; Predicting relationship between the people in the image.
              </div>
              <div class="links">
                    <a href="https://github.com/zhuhd15/Demo-System">[Code]</a> 
              </div>
            </td>
            </tr>

          </tbody>
          <tbody> 
            <tr>
              <td class="pro_td1"><img src="project/img/processed/va-similarity.jpg" class="papericon"></td>
              <td class="pub_td2">
              <div class="title">
                <b>Visual-audio Similarity Evaluation System  </b>
              </div>
              <div class="description">
                   &bull; Evaluating similarity between given audio and visual fragments.<br/>
                   &bull; Sequence feature extraction and similarity evaluation.
              </div>
              <div class="links">
                    <a href="https://github.com/haidongz-usc/VA-Project">[Code]</a> 
              </div>
            </td>
            </tr>

          </tbody>
          <tbody> 
            <tr>
              <td class="pro_td1"><img src="project/img/processed/lecture-management-system.png" class="papericon"></td>
              <td class="pub_td2">
              <div class="title">
                <b>Competition & Lecture Management System  </b>
              </div>
              <div class="description">
                   &bull; Lecture management system with wechat and website version.<br/>
                   &bull; Organizing information according to user's habit and need.
              </div>
              <div class="links">
                    <a href="https://github.com/zhuhd15/CLMS-SigmaGo">[Code]</a> 
              </div>
            </td>
            </tr>

          </tbody>
        </table>

        <!-- Acknowledgements -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
            <br/>
            <p align="right">
            <font size="2">
            Website source from <a href="https://jonbarron.info">Jon Barron</a> and <a href="http://people.csail.mit.edu/xingyuan/">Xingyuan Sun</a>.
            </font>
            </p>
        </tr>
        </table>


      </td>
    </tr>
  </table>
</body>
</html>
